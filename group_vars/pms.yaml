---
pms_ip: 10.42.1.1
pms_hostname: soulpms

# ironicbadger.figurine
figurine_name: "{{ pms_hostname }}"

# grog.package
package_list:
  - name: bash-completion
  - name: curl
  - name: fio
  - name: git
  - name: hddtemp
  - name: htop
  - name: iftop
  - name: intel-gpu-tools
  - name: iotop
  - name: lm-sensors
  - name: mc
  - name: mergerfs
  - name: mutt
  - name: ncdu
  - name: net-tools
  - name: nfs-kernel-server
  - name: nmap
  - name: nvme-cli
  - name: openssh-server
  - name: python3
  - name: python-setuptools
  - name: screen
  - name: ssh-import-id
  - name: smartmontools
  - name: sudo
  - name: tmux
  - name: tree
  - name: wget
  - name: xfsprogs
  - name: zfsutils-linux

# ironicbadger.snapraid
snapraid_bin_path: /usr/bin/snapraid
snapraid_parity_disks:
  - { path: /mnt/parity1, diskbyid: /dev/disk/by-id/ata-WDC_WD140EDGZ-11B1PA0_9LJ0AGVG-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/parity2, diskbyid: /dev/disk/by-id/ata-WDC_WD140EDGZ-11B1PA0_9MHSD18U-part1, fs: xfs, opts: defaults, content: false }
snapraid_data_disks:
  - { path: /mnt/disk1, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_7SJNRD5W-part1, fs: xfs, opts: defaults, content: true }
  - { path: /mnt/disk2, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_7SH07NTC-part1, fs: xfs, opts: defaults, content: true }
  - { path: /mnt/disk3, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHJ8NPG-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk4, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHK2T1W-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk5, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHJZ2AW-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk6, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHJ6LEG-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk7, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHK1KPW-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk8, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_1SJ9HZPZ-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk9, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_1SH24AMZ-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk10, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SGHHN6C-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk11, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SGEPKNC-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk12, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SHJ2YGG-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk13, diskbyid: /dev/disk/by-id/ata-WDC_WD80EFAX-68LHPN0_7SGD2B6C-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk14, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_1SJ9MDTZ-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk15, diskbyid: /dev/disk/by-id/ata-WDC_WD80EMAZ-00WJTA0_7SJRD46U-part1, fs: xfs, opts: defaults, content: false }
  - { path: /mnt/disk16, diskbyid: /dev/disk/by-id/ata-WDC_WD140EDGZ-11B1PA0_9MH5L4GK-part1, fs: xfs, opts: defaults, content: true }
snapraid_content_files:
  - path: /mnt/tank/fuse/documents/.snapraid.content
snapraid_config_excludes:
  - "*.unrecoverable"
  - "/tmp/"
  - "/lost+found/"
  - "downloads/"
  - "appdata/"
  - "*.!sync"
  - ".AppleDouble"
  - "._AppleDouble"
  - ".DS_Store"
  - "._.DS_Store"
  - ".Thumbs.db"
  - ".fseventsd"
  - ".Spotlight-V100"
  - ".TemporaryItems"
  - ".Trashes"
  - ".AppleDB"
  - ".nfo"
  - "Proxmox/"
  - "Backups/"

# NVME
#/dev/disk/by-id/nvme-eui.e8238fa6bf530001001b448b490a15d3-part1 /mnt/nvme1 xfs defaults 0 0

fstab_mergerfs:
  - { source: "/mnt/disk*", mountpoint: "{{ data_path }}", fs: fuse.mergerfs, opts: "defaults,nonempty,allow_other,use_ino,moveonenospc=true,category.create=mfs,dropcacheonclose=true,minfreespace=250G,fsname=MergerFS" }  

snapraid_runner: true
snapraid_email_address: "{{ secret_snapraid_email_address }}"
snapraid_gmail_pass: "{{ secret_snapraid_gmail_pass }}"
snapraid_healthcheck_io_host: "https://hc.{{ secret_domain_cloud }}"
snapraid_healthcheck_io_uuid: "{{ snapraid_healthchecks_id }}"

## telegraf
telegraf_plugins_base:
  - name: mem
  - name: system
  - name: cpu
    options:
      percpu: "true"
      totalcpu: "true"
      collect_cpu_time: "false"
      report_active: "false"
  - name: disk
    options:
      ignore_fs:
        - "tmpfs"
        - "devtmpfs"
        - "devfs"
      mountpoints:
        - "/"
        - "/mnt/disk1"
        - "/mnt/disk2"
        - "/mnt/disk3"
        - "/mnt/disk4"
        - "/mnt/disk5"
        - "/mnt/disk6"
        - "/mnt/disk7"
        - "/mnt/disk8"
        - "/mnt/disk9"
        - "/mnt/disk10"
        - "/mnt/disk11"
        - "/mnt/disk12"
        - "/mnt/disk13"
        - "/mnt/disk14"
        - "/mnt/disk15"
        - "/mnt/disk16"
        - "/mnt/parity1"
        - "/mnt/parity2"
        - "/mnt/storage"
        - "/mnt/tank"
  - name: diskio
    options:
      skip_serial_number: "true"
  - name: kernel
  - name: processes
  - name: docker
    options:
      endpoint: "unix:///var/run/docker.sock"
      perdevice: "true"
  - name: hddtemp
  - name: net
    options:
      interfaces:
        - "eno1"

# ntd.nut
nut_mode: netclient
nut_host: 10.42.1.2
nut_user: SoulDeity
nut_password: "{{ secret_soulnut_pass }}"
nut_role: slave
nut_packages:
  - nut-client
nut_ups:
  - name: CyberPower
    driver: usbhid-ups
    device: auto
    description: CyberPower 1500 UPS
nut_upsmon_extra: |
  RUN_AS_USER root

  MINSUPPLIES 1
  SHUTDOWNCMD "/sbin/shutdown -h"
  NOTIFYCMD /usr/sbin/upssched
  POLLFREQ 2
  POLLFREQALERT 1
  HOSTSYNC 15
  DEADTIME 15
  POWERDOWNFLAG /etc/killpower

  NOTIFYMSG ONLINE    "UPS %s on line power"
  NOTIFYMSG ONBATT    "UPS %s on batter"
  NOTIFYMSG LOWBATT   "UPS %s battery is low"
  NOTIFYMSG FSD       "UPS #s: forced shutdown in progress"
  NOTIFYMSG COMMOK    "Communications with UPS %s established"
  NOTIFYMSG COMMBAD   "Communications with UPS %s lost"
  NOTIFYMSG SHUTDOWN  "Auto logout and shutdown proceeding"
  NOTIFYMSG REPLBATT  "UPS %s batter needs to be replaced"
  NOTIFYMSG NOCOMM    "UPS %s is unavailable"
  NOTIFYMSG NOPARENT  "upsmon parent process died - shutdown impossible"

  NOTIFYMSG ONLINE    SYSLOG+WALL+EXEC
  NOTIFYMSG ONBATT    SYSLOG+WALL+EXEC
  NOTIFYMSG LOWBATT   SYSLOG+WALL
  NOTIFYMSG FSD       SYSLOG+WALL+EXEC
  NOTIFYMSG COMMOK    SYSLOG+WALL+EXEC
  NOTIFYMSG COMMBAD   SYSLOG+WALL+EXEC
  NOTIFYMSG SHUTDOWN  SYSLOG+WALL+EXEC
  NOTIFYMSG REPLBATT  SYSLOG+WALL
  NOTIFYMSG NOCOMM    SYSLOG+WALL+EXEC
  NOTIFYMSG NOPARENT  SYSLOG+WALL

  RBWARNTIME 43200
  NOCOMMWARNTIME 600
  FINALDELAY 5
# configure /etc/nut/upssched.conf with the following
  # CMDSCRIPT /etc/nut/upssched-cmd
  # PIPEFN /etc/nut/upssched.pipe
  # LOCKFN /etc/nut/upssched.lock
  #
  # AT ONBATT * START-TIMER onbatt 30
  # AT ONLINE * CANCEL-TIMER onbatt online
  # AT ONBATT * START-TIMER earlyshutdown 30
  # AT ONLINE * CANCEL-TIMER earlyshutdown online
  # AT LOWBATT * EXECUTE onbatt
  # AT COMMBAD * START-TIMER commbad 30
  # AT COMMOK * CANCEL-TIMER commbad commok
  # AT NOCOMM * EXECUTE commbad
  # AT SHUTDOWN * EXECUTE powerdown
# configure /etc/nut/upssched-cmd with the following
  #  !/bin/sh
  #    case $1 in
  #      onbatt)
  #        logger -t upssched-cmd "The UPS is on battery"
  #        ;;
  #      earlyshutdown)
  #        logger -t upssched-cmd "UPS on battery too long, forced shutdown"
  #        /usr/sbin/upsmon -c fsd
  #       ;;
  #      shutdowncritical)
  #        logger -t upssched-cmd "UPS on battery critical, forced shutdown"
  #        /usr/sbin/upsmon -c fsd
  #       ;;
  #      upsgone)
  #        logger -t upssched-cmd "The UPS has been gone for awhile"
  #        ;;
  #      *)
  #        logger -t upssched-cmd "Unrecognized command: $1"
  #        ;;
  #    esac

# ironicbadger.ansible_role_bash_aliases
bash_aliases:
  - { alias: "ls", command: "ls --color=auto"}
  - { alias: "ll", command: "ls -la"}
  - { alias: "df", command: "df -h -x aufs -x tmpfs -x udev"}
  - { alias: "du", command: "du -ch"}
  - { alias: "c", command: "clear"}
  - { alias: "dtail", command: "docker logs -tf --tail='50' " }
  - { alias: "dstop", command: "docker stop `docker ps -aq`" }
  - { alias: "drm", command: "docker rm `docker ps -aq`" }
  - { alias: "dcp", command: "docker-compose -f ~/docker-compose.yml "}
  - { alias: "dcporph", command: "docker-compose -f ~/docker-compose.yml up -d --remove-orphans"}
  - { alias: "dprune", command: "docker image prune" }
  - { alias: "dprunesys", command: "docker system prune --all" }
  - { alias: "dtop", command: "docker run --name ctop  -it --rm -v /var/run/docker.sock:/var/run/docker.sock quay.io/vektorlab/ctop"}
  - { alias: "appdata", command: "cd /mnt/tank/appdata" }
  - { alias: "zspace", command: "zfs list -o space" }
  - { alias: "zsnap", command: "zfs list -t snapshot" }
  - { alias: "dfclean", command: "df -h -x tmpfs -x zfs -t fuse.mergerfs -t xfs -t ext4"}
  - { alias: "dffull", command: "df -h -x tmpfs -t fuse.mergerfs -t xfs -t ext4 -t zfs"}
  - { alias: "hdtemp", command: "sudo hddtemp /dev/sd[a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r]"}

# soulpms
docker_zfs_override: true
extra_mountpoints:
  - { path: "{{ data_path }}" }

# soultraefik
traefik_file_provider: true
traefik_enable_dashboard: false #defaults to false
traefik_insecure_transport: true #defaults to false
traefik_exposed_by_default: false

## soulauthelia
authelia_users:
  - username: "{{ authelia_username }}"
    displayname: "{{ authelia_displayname }}"
    # docker run authelia/authelia:latest authelia hash-password 'yourpassword'
    password: "{{ authelia_password }}"
    email: "{{ authelia_email_address }}"
    groups:
      - admin
      - dev
authelia_rules:
  - domain: "*.{{ secret_domain_full }}" # allows api's through
    policy: bypass
    resources:
      - '^/api.*$'
  - domain: "*.{{ secret_domain_full }}" # allows calendar feeds through
    policy: bypass
    resources:
      - '^/feed.*$'
  - domain: "*.{{ secret_domain_full }}"
    policy: two_factor
  - domain: "plex.{{ secret_domain_full }}"
    policy: one_factor
  - domain: "drive.{{ secret_domain_full }}"
    policy: bypass

# soulrestic
restic_backup_locations:
  - /mnt/tank
restic_backup_excludes: #defaults to blank
  - /mnt/tank/appdata/plex/Library/Application Support/Plex Media Server/Cache
  - /mnt/tank/appdata/plex/Library/Application Support/Plex Media Server/Media
  - /mnt/tank/appdata/plexmeta
restic_forget: true #defaults to false

# ironicbadger.docker_compose_generator
appdata_path: /mnt/tank/appdata
download_path: /mnt/storage/downloads
data_path: /mnt/storage
containers:
###
  - service_name: traefik
    image: traefik
    container_name: tr
    hostname: tr
    active: true
    extra_hosts:
      - host.docker.internal:172.17.0.1
    volumes:
      - "{{ appdata_path }}/traefik:/etc/traefik"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    environment:
      - "CLOUDFLARE_EMAIL={{ secret_cloudflare_email }}"
      - "CLOUDFLARE_API_KEY={{ secret_cloudflare_api }}"
    ports:
      - "80:80"
      - "443:443"
      - "8081:8080"
    restart: unless-stopped
  ###
  - service_name: authelia
    image: authelia/authelia
    container_name: authelia
    hostname: authelia
    active: true
    volumes:
      - "{{ appdata_path }}/authelia:/config"
    expose:
    labels:
      - traefik.enable=true
      - "traefik.http.routers.authelia.rule=Host(`login.{{ secret_domain_full }}`)"
      - traefik.http.routers.authelia.tls=true
      - traefik.http.services.authelia.loadbalancer.server.port=9091
      - "traefik.http.middlewares.authelia.forwardauth.address=http://authelia:9091/api/verify?rd=https://login.{{ secret_domain_full }}/"
      - traefik.http.middlewares.authelia.forwardauth.trustForwardHeader=true
      - traefik.http.middlewares.authelia.forwardauth.authResponseHeaders=Remote-User,Remote-Groups,Remote-Name,Remote-Email
    restart: unless-stopped
  - service_name: auth-redis
    image: redis
    container_name: auth-redis
    hostname: auth-redis
    active: true
    volumes:
      - "{{ appdata_path }}/redis/authelia:/data"
    restart: unless-stopped
  ###
  - service_name: scrutiny
    image: ghcr.io/analogj/scrutiny:master-omnibus
    container_name: scrutiny
    hostname: scrutiny
    active: true
    cap_add:
      - SYS_RAWIO
      - SYS_ADMIN
    devices:
      - /dev:/dev
    volumes:
      - "{{ appdata_path }}/scrutiny/config:/opt/scrutiny/config"
      - "{{ appdata_path }}/scrutiny/influxdb:/opt/scrutiny/influxdb"
      - /run/udev:/run/udev:ro
    ports:
      - "7278:8080" # webapp
      - "8087:8086" # influxDB admin
    include_global_env_vars: true
    privileged: true
    restart: unless-stopped
  ###
  - service_name: plex
    image: ghcr.io/linuxserver/plex
    container_name: plex
    hostname: plex
    active: true
    network_mode: host
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - "{{ appdata_path }}/plex:/config"
      - /dev/shm:/config/transcodes
      - "{{ data_path }}:/data:ro"
    environment:
      - VERSION=docker
    labels:
      - traefik.enable=true
      - "traefik.http.routers.plex.rule=Host(`plex.{{ secret_domain_full }}`)"
      - traefik.http.services.plex.loadbalancer.server.port=32400
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: plexmeta
    image: meisnate12/plex-meta-manager
    container_name: plexmeta
    hostname: plexmeta
    active: true
    volumes:
      - "{{ appdata_path }}/plexmeta/config:/config"
    environment:
      - PMM_TIME=01:22
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: tautulli
    image: ghcr.io/linuxserver/tautulli
    container_name: tautulli
    hostname: tautulli
    active: true
    depends_on:
      - plex
    volumes:
      - "{{ appdata_path }}/tautulli:/config"
      - "{{ appdata_path }}/plex/Library/Application Support/Plex Media Server/Logs:/logs:ro"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.tautulli.rule=Host(`tautulli.{{ secret_domain_full }}`)"
      - traefik.http.services.tautulli.loadbalancer.server.port=8181
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: nzbget 
    image: ghcr.io/linuxserver/nzbget
    container_name: nzbget
    hostname: nzbget
    active: true
    volumes:
      - "{{ appdata_path }}/nzbget:/config"
      - "{{ download_path }}:/downloads"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.nzbget.rule=Host(`nzbget.{{ secret_domain_full }}`)"
      - traefik.http.routers.nzbget.middlewares=authelia@docker
      - traefik.http.services.nzbget.loadbalancer.server.port=6789
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: prowlarr
    image: ghcr.io/linuxserver/prowlarr:develop
    container_name: prowlarr
    hostname: prowlarr
    active: true
    volumes:
      - "{{ appdata_path }}/prowlarr:/config"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.prowlarr.rule=Host(`prow.{{ secret_domain_full }}`)"
      - traefik.http.routers.prowlarr.middlewares=authelia@docker
      - traefik.http.services.prowlarr.loadbalancer.server.port=9696
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: sonarr
    image: ghcr.io/linuxserver/sonarr
    container_name: sonarr
    hostname: sonarr
    active: true
    depends_on:
      - nzbget
      - prowlarr
    volumes:
      - "{{ appdata_path }}/sonarr:/config"
      - "{{ download_path }}:/downloads"
      - "{{ data_path }}:/data"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.sonarr.rule=Host(`sonarr.{{ secret_domain_full }}`)"
      - traefik.http.routers.sonarr.middlewares=authelia@docker
      - traefik.http.services.sonarr.loadbalancer.server.port=8989
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: radarr
    image: ghcr.io/linuxserver/radarr
    container_name: radarr
    hostname: radarr
    active: true
    depends_on:
      - nzbget
      - prowlarr
    volumes:
      - "{{ appdata_path }}/radarr:/config"
      - "{{ download_path }}:/downloads"
      - "{{ data_path }}:/data"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.radarr.rule=Host(`radarr.{{ secret_domain_full }}`)"
      - traefik.http.routers.radarr.middlewares=authelia@docker
      - traefik.http.services.radarr.loadbalancer.server.port=7878
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: audiobookshelf
    image: ghcr.io/advplyr/audiobookshelf
    container_name: audiobookshelf
    hostname: audiobookshelf
    active: true
    volumes:
      - "{{ appdata_path }}/audiobookshelf/metadata:/metadata"
      - "{{ appdata_path }}/audiobookshelf/config:/config"
      - "{{ data_path }}:/data:ro"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.audiobookshelf.rule=Host(`abs.{{ secret_domain_full }}`)"
      - traefik.http.services.audiobookshelf.loadbalancer.server.port=80
    restart: unless-stopped
  ###
  - service_name: readarr
    image: lscr.io/linuxserver/readarr:nightly
    container_name: readarr
    hostname: readarr
    active: true
    depends_on:
      - nzbget
      - prowlarr
    volumes:
      - "{{ appdata_path }}/readarr:/config"
      - "{{ download_path }}:/downloads"
      - "{{ data_path }}:/data"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.readarr.rule=Host(`readarr.{{ secret_domain_full }}`)"
      - traefik.http.routers.readarr.middlewares=authelia@docker
      - traefik.http.services.readarr.loadbalancer.server.port=8787
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: overseerr
    image: ghcr.io/linuxserver/overseerr
    container_name: overseerr
    hostname: overseerr
    active: true
    volumes:
      - "{{ appdata_path }}/overseerr:/config"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.overseerr.rule=Host(`overseerr.{{ secret_domain_full }}`)"
      - traefik.http.services.overseerr.loadbalancer.server.port=5055
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: organizr
    image: ghcr.io/organizr/organizr
    container_name: organizr
    hostname: organizr
    active: true
    volumes:
      - "{{ appdata_path }}/organizr:/config"
    environment:
      - fpm=true
      - branch=v2-master
    labels:
      - traefik.enable=true
      - "traefik.http.routers.main.rule=Host(`main.{{ secret_domain_full }}`)"
      - traefik.http.services.main.loadbalancer.server.port=80
      - traefik.http.middlewares.limit.buffering.maxRequestBodyBytes=128000
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: bitwarden
    image: vaultwarden/server
    container_name: bitwarden
    hostname: bitwarden
    active: true
    volumes:
      - "{{ appdata_path }}/bitwarden:/data"
    environment:
      - SIGNUPS_ALLOWED=false
      - WEBSOCKET_ENABLED=true
      - "DOMAIN=https://vault.{{ secret_domain_full }}"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.bitwarden.rule=Host(`vault.{{ secret_domain_full }}`)"
      - traefik.http.services.bitwarden.loadbalancer.server.port=80
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: nextcloud
    image: ghcr.io/linuxserver/nextcloud
    container_name: nextcloud
    hostname: nextcloud
    active: true
    depends_on:
      - nextcloud-db
      - nc-redis
    volumes:
      - "{{ appdata_path }}/nextcloud:/config"
      - "{{ appdata_path }}/nextcloud/data:/data"
    environment:
      - DOCKER_MODS=theorangeone/lsio-mod-more-processes:latest
    labels:
      - traefik.enable=true
      - "traefik.http.routers.nextcloud.rule=Host(`drive.{{ secret_domain_full }}`)"
      - traefik.http.routers.nextcloud.tls.certresolver=cloudflare
      - traefik.http.services.nextcloud-nextcloud.loadbalancer.server.port=443
      - traefik.http.services.nextcloud-nextcloud.loadbalancer.server.scheme=https
      - traefik.http.middlewares.nextcloud-hsts.headers.stsseconds=15552000
      - traefik.http.routers.nextcloud.middlewares=nextcloud-hsts@docker
    include_global_env_vars: true
    restart: unless-stopped
  - service_name: nextcloud-db
    image: ghcr.io/linuxserver/mariadb
    container_name: nextcloud-db
    hostname: nextcloud-db
    active: true
    volumes:
      - "{{ appdata_path }}/nextcloud-db:/config"
    environment:
      - MYSQL_DATABASE=nextcloud
      - MYSQL_USER=souldeity
      - "MYSQL_PASSWORD={{ secret_nextclouddb_pass }}"
      - "MYSQL_ROOT_PASSWORD={{ secret_nextclouddb_pass }}"
    ports:
      - "3306:3306"
    include_global_env_vars: true
    restart: unless-stopped
  - service_name: nc-redis
    image: redis:alpine
    container_name: nc-redis
    hostname: nc-redis
    active: true
    volumes:
      - "{{ appdata_path }}/redis/nextcloud:/data"
    restart: unless-stopped
  ###
  - service_name: paperless
    image: ghcr.io/paperless-ngx/paperless-ngx:latest
    container_name: paperless
    hostname: paperless
    active: true
    depends_on:
      - pl-redis
    volumes:
      - "{{ appdata_path }}/paperless/config:/usr/src/paperless/data"
      - "{{ appdata_path }}/paperless/data/media:/usr/src/paperless/media"
      - "{{ appdata_path }}/paperless/data/consume:/usr/src/paperless/consume"
      - "{{ appdata_path }}/paperless/data/export:/usr/src/paperless/export"
    environment:
      - "PAPERLESS_SECRET_KEY={{ secret_paperless_key }}"
      - "PAPERLESS_URL=https://paperless.{{ secret_domain_full }}"
      - "PAPERLESS_TIME_ZONE={{ ntp_timezone }}"
      - PAPERLESS_FILENAME_FORMAT="{created_year}/{correspondent}/{created} {title}"
      - PAPERLESS_CONSUMER_RECURSIVE=true
      - PAPERLESS_CONSUMER_SUBDIRS_AS_TAGS=true
      - PAPERLESS_REDIS=redis://pl-redis:6379
    labels:
      - traefik.enable=true
      - "traefik.http.routers.paperless.rule=Host(`paperless.{{ secret_domain_full }}`)"
      - traefik.http.routers.paperless.middlewares=authelia@docker
      - traefik.http.services.paperless.loadbalancer.server.port=8000
    include_global_env_vars: false
    restart: unless-stopped
  - service_name: pl-redis
    image: redis:6.0
    container_name: pl-redis
    hostname: pl-redis
    active: true
    volumes:
      - "{{ appdata_path }}/redis/paperless:/data"
    restart: unless-stopped
  ###
  - service_name: mealie
    image: hkotel/mealie
    container_name: mealie
    hostname: mealie
    active: true
    volumes:
      - "{{ appdata_path }}/mealie:/app/data"
    labels:
      - traefik.enable=true
      - "traefik.http.routers.mealie.rule=Host(`mealie.{{ secret_domain_full }}`)"
      - traefik.http.services.mealie.loadbalancer.server.port=80
    include_global_env_vars: true
    restart: unless-stopped
  ###
  - service_name: nginx_recipes
    image: nginx:mainline-alpine
    active: true
    volumes:
      - "{{ appdata_path }}/tandoor/static:/static:ro"
      - "{{ appdata_path }}/tandoor/media:/media:ro"
      - "{{ appdata_path }}/tandoor/nginx:/etc/nginx/conf.d:ro"
    env_file:
      - "{{ appdata_path }}/tandoor/docker/.env"
    depends_on:
      - web_recipes
    labels:
      - traefik.enable=true
      - "traefik.http.routers.tandoor.rule=Host(`recipes.{{ secret_domain_full }}`)"
      - traefik.http.services.tandoor.loadbalancer.server.port=80
    restart: unless-stopped
  ###
  - service_name: web_recipes
    image: vabene1111/recipes
    active: true
    volumes:
      - "{{ appdata_path }}/tandoor/static:/opt/recipes/staticfiles"
      - "{{ appdata_path }}/tandoor/media:/opt/recipes/mediafiles"
      - "{{ appdata_path }}/tandoor/nginx:/etc/nginx/conf.d"
    env_file:
      - "{{ appdata_path }}/tandoor/docker/.env"
    depends_on:
      - db_recipes
    restart: unless-stopped
  ###
  - service_name: db_recipes
    image: postgres:11-alpine
    active: true
    volumes:
      - "{{ appdata_path }}/tandoor/db:/var/lib/postgresql/data"
    env_file:
      - "{{ appdata_path }}/tandoor/docker/.env"
    restart: unless-stopped
  ###
  - service_name: webnut
    image: teknologist/webnut
    container_name: webnut
    hostname: webnut
    active: true
    environment:
      - UPS_HOST=10.42.1.2
      - UPS_PORT=3493
      - UPS_USER=monuser
      - "UPS_PASSWORD={{ secret_soulnut_pass }}"
    ports:
      - 6543:6543
    security_opt:
      - no-new-privileges:true
    include_global_env_vars: false
    restart: unless-stopped
  ###
  - service_name: actual
    image: jlongster/actual-server
    container_name: actual
    hostname: actual
    active: true
    volumes:
      - "{{ appdata_path }}/actual/server-files:/app/server-files"
      - "{{ appdata_path }}/actual/user-files:/app/user-files"
    ports:
      - "5006:5006"
    include_global_env_vars: false
    restart: unless-stopped
  ###

# template for docker-compose services
#  - service_name:
#    image:
#    container_name:
#    hostname:
#    active: true
#    volumes:
#      - "{{ appdata_path }}/app:/config"
#    environment:
#      -
#    labels:
#      - traefik.enable=true
#      - "traefik.http.routers.XXXX.rule=Host(`XXXX.{{ secret_domain_full }}`)"
#      - traefik.http.routers.XXXX.middlewares=authelia@docker
#      - traefik.http.services.XXXX.loadbalancer.server.port=XXXX
#    include_global_env_vars: true
#    restart: unless-stopped
  ###